{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 11\n",
      "[2 4 3 3 1 1 0 1 1 3]\n",
      "[2 4 3 3 1 1 0 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "\n",
    "class KernelKMeans(BaseEstimator, ClusterMixin):\n",
    "    \"\"\"\n",
    "    Kernel K-means\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Kernel k-means, Spectral Clustering and Normalized Cuts.\n",
    "    Inderjit S. Dhillon, Yuqiang Guan, Brian Kulis.\n",
    "    KDD 2004.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=3, max_iter=50, tol=1e-3, random_state=None,\n",
    "                 kernel=\"linear\", gamma=None, degree=3, coef0=1,\n",
    "                 kernel_params=None, verbose=0):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.kernel_params = kernel_params\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    @property\n",
    "    def _pairwise(self):\n",
    "        return self.kernel == \"precomputed\"\n",
    "\n",
    "    def _get_kernel(self, X, Y=None):\n",
    "        if callable(self.kernel):\n",
    "            params = self.kernel_params or {}\n",
    "        else:\n",
    "            params = {\"gamma\": self.gamma,\n",
    "                      \"degree\": self.degree,\n",
    "                      \"coef0\": self.coef0}\n",
    "        return pairwise_kernels(X, Y, metric=self.kernel,\n",
    "                                filter_params=True, **params)\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        K = self._get_kernel(X)\n",
    "\n",
    "        sw = sample_weight if sample_weight else np.ones(n_samples)\n",
    "        self.sample_weight_ = sw\n",
    "\n",
    "        rs = check_random_state(self.random_state)\n",
    "        self.labels_ = rs.randint(self.n_clusters, size=n_samples)\n",
    "\n",
    "        dist = np.zeros((n_samples, self.n_clusters))\n",
    "        self.within_distances_ = np.zeros(self.n_clusters)\n",
    "\n",
    "        for it in range(self.max_iter):\n",
    "            dist.fill(0)\n",
    "            self._compute_dist(K, dist, self.within_distances_,\n",
    "                               update_within=True)\n",
    "            labels_old = self.labels_\n",
    "            self.labels_ = dist.argmin(axis=1)\n",
    "\n",
    "            # Compute the number of samples whose cluster did not change \n",
    "            # since last iteration.\n",
    "            n_same = np.sum((self.labels_ - labels_old) == 0)\n",
    "            if 1 - float(n_same) / n_samples < self.tol:\n",
    "                if self.verbose:\n",
    "                    print(\"Converged at iteration\", it + 1)\n",
    "                break\n",
    "\n",
    "        self.X_fit_ = X\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _compute_dist(self, K, dist, within_distances, update_within):\n",
    "        \"\"\"Compute a n_samples x n_clusters distance matrix using the \n",
    "        kernel trick.\"\"\"\n",
    "        sw = self.sample_weight_\n",
    "\n",
    "        for j in range(self.n_clusters):\n",
    "            mask = self.labels_ == j\n",
    "\n",
    "            if np.sum(mask) == 0:\n",
    "                raise ValueError(\"Empty cluster found, try smaller n_cluster.\")\n",
    "\n",
    "            denom = sw[mask].sum()\n",
    "            denomsq = denom * denom\n",
    "\n",
    "            if update_within:\n",
    "                KK = K[mask][:, mask]  # K[mask, mask] does not work.\n",
    "                dist_j = np.sum(np.outer(sw[mask], sw[mask]) * KK / denomsq)\n",
    "                within_distances[j] = dist_j\n",
    "                dist[:, j] += dist_j\n",
    "            else:\n",
    "                dist[:, j] += within_distances[j]\n",
    "\n",
    "            dist[:, j] -= 2 * np.sum(sw[mask] * K[:, mask], axis=1) / denom\n",
    "\n",
    "    def predict(self, X):\n",
    "        K = self._get_kernel(X, self.X_fit_)\n",
    "        n_samples = X.shape[0]\n",
    "        dist = np.zeros((n_samples, self.n_clusters))\n",
    "        self._compute_dist(K, dist, self.within_distances_,\n",
    "                           update_within=False)\n",
    "        return dist.argmin(axis=1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from sklearn.datasets import make_blobs\n",
    "    X, y = make_blobs(n_samples=1000, centers=5, random_state=0)\n",
    "\n",
    "    km = KernelKMeans(n_clusters=5, max_iter=100, random_state=0, verbose=1)\n",
    "    print(km.fit_predict(X)[:10])\n",
    "    print(km.predict(X[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
